{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprawozdanie z projektu\n",
    "### Autor\n",
    "Marcin Bździuch, 99367\n",
    "\n",
    "## Cel projektu\n",
    "Celem projektu było stworzenie dwóch klasyfikatorów dla zbioru danych z Protein Data Bank. Pierwszy klasyfikator operował na oryinalnych klasach (nazwach ligandu), drugi na klasach grupowych (zgrupowane nazwy ligandu).\n",
    "\n",
    "## Narzędzia\n",
    "Do realizacji projektu wykorzystano:\n",
    "\n",
    "* Język Python 2.7.10\n",
    "* Bibliotekę pandas\n",
    "* Bibliotekę scikit-learn\n",
    "* IPython Notebook\n",
    "\n",
    "## Użycie aplikacji\n",
    "W efekcie końcowym powstał skrypt języka Python `main.py`, który dokonuje wczytania i oczyszczenia danych z pliku CSV (`preprocess`), wyszukania najlepszego klasyfikatora dla klas oryginalnych (`search`) i klas grupowych (`searchg`) oraz dokonania klasyfikacji zbioru testowego za pomocą pierwszego klasyfikatora (`classify`) i drugiego (`classifyg`).\n",
    "\n",
    "Użycie:\n",
    "`python main.py OPCJE...`\n",
    "\n",
    "| parametr | znaczenie |\n",
    "| ---------|-----------|\n",
    "| `data preprocess` | Wczytanie danych z pliku `all_summary.txt` i oczyszczenie danych. Wynikiem jest zserializowany w pliku `cache/df` DataFrame  zawierający oczyszczone dane. |\n",
    "| `test preprocess` | To samo co `data preprocess`, tylko dane zostaną wczytane z pliku `test_summary.txt`. Opcja służy do testowania skryptu na mniejszym (testowym) zbiorze danych. |\n",
    "| `search` | Wczytanie DataFrame `cache/df` z danymi i wyszukanie najlepszego klasyfikatora operującego na klasach oryginalnych. Wynikiem jest klasyfikator zserializowany w pliku `cache/es`. |\n",
    "| `searchg` | To samo co `search` tylko wynikowy klasyfikator operuje na klasach grupowych wczytanych z pliku `grouped_res_name.txt`. Wynikiem jest klasyfikator zserializowany w pliku `cache/esg`. |\n",
    "| `classify` | Wczytuje klasyfikator `cache/es`, DataFrame `cache/df` i dane testowe z pliku `test_data.txt`, które następnie są poddawane klasyfikacji. Wynikiem jest wektor klas zapisany w pliku `results/classify.txt`. |\n",
    "| `classifyg` | To samo co `classify` tylko działający na klasyfikatorze dla klas grupowych `cache/esg`. Wynikiem jest wektor klas grupowych zapisany w pliku `results/classifyg.txt`. |\n",
    "\n",
    "Opcje można dowolnie łączyć w łańcuchy, np.:\n",
    "\n",
    "`python main.py data preprocess search classify`\n",
    "\n",
    "spowoduje wykonanie wszystkich czynności: wczytanie i oczyszczenie danych, wyszukanie klasyfikatora i klasyfikację zbioru testowego.\n",
    "\n",
    "`python main.py data preprocess search searchg classify classifyg`\n",
    "\n",
    "spowoduje wykonanie wszystkich czynności dla obu klasyfikatorów.\n",
    "\n",
    "**UWAGA** - przed użyciem aplikacji należy wypakować wszystkie pliki z danymi z archiwów `all_summary.7z` i `test_data.7z`.\n",
    "\n",
    "## Opis kroków\n",
    "\n",
    "### Wczytanie i oczyszczenie danych\n",
    "Pierwszym krokiem było wczytanie i oczyszczenie danych wejściowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "\tfile = 'all_summary.txt'\n",
    "\tdf = read_data(file, ';')\n",
    "\tdf = remove_ignored_classes(df)\n",
    "\tdf = remove_duplicates(df)\n",
    "\tdf = remove_rare_classes(df)\n",
    "\tdf = remove_ignored_columns(df)\n",
    "\tdf = df.fillna(0)\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na oczyszczenie danych składały się 4 fazy.\n",
    "1 - Usunięcie ignorowanych klas ze zbioru danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_ignored_classes(df):\n",
    "\tignored_classes = {'DA','DC','DT', 'DU',\n",
    "\t\t'DG', 'DI','UNK', 'UNX',\n",
    "\t\t'UNL', 'PR', 'PD', 'Y1',\n",
    "\t\t'EU', 'N', '15P', 'UQ',\n",
    "\t\t'PX4'}\n",
    "\treturn df[~df.res_name.isin(ignored_classes) & ~df.res_name.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 - Usunięcie obserwacji, które są zwielokrotnione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "\treturn df.drop_duplicates(subset = ['res_name', 'pdb_code'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 - Usunięcie obserwacji, które należą do klas występujących zbyt rzadko (mniej niż 5 wystąpień):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_rare_classes(df):\n",
    "\tclass_sizes = df.groupby(['res_name']).size()\n",
    "\trare_classes = set(class_sizes[class_sizes < 5].index)\n",
    "\treturn df[~df.res_name.isin(rare_classes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 - Usunięcie kolumn niedostępnych w klasyfikowanym zbiorze testowym:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_ignored_columns(df):\n",
    "\tignored_columns = ['title', 'pdb_code', 'res_id', 'chain_id',\n",
    "\t\t'local_BAa', 'local_NPa', 'local_Ra', 'local_RGa',\n",
    "\t\t'local_SRGa', 'local_CCSa', 'local_CCPa', 'local_ZOa',\n",
    "\t\t'local_ZDa', 'local_ZD_minus_a', 'local_ZD_plus_a', 'local_res_atom_count',\n",
    "\t\t'local_res_atom_non_h_count', 'local_res_atom_non_h_occupancy_sum',\n",
    "\t\t'local_res_atom_non_h_electron_sum', 'local_res_atom_non_h_electron_occupancy_sum',\n",
    "\t\t'local_res_atom_C_count', 'local_res_atom_N_count', 'local_res_atom_O_count',\n",
    "\t\t'local_res_atom_S_count', 'dict_atom_non_h_count', 'dict_atom_non_h_electron_sum',\n",
    "\t\t'dict_atom_C_count', 'dict_atom_N_count', 'dict_atom_O_count', 'dict_atom_S_count',\n",
    "\t\t'fo_col', 'fc_col', 'weight_col', 'grid_space',\n",
    "\t\t'solvent_radius', 'solvent_opening_radius', 'part_step_FoFc_std_min',\n",
    "\t\t'part_step_FoFc_std_max','part_step_FoFc_std_step', 'resolution_max_limit']\n",
    "\treturn df.drop(ignored_columns, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyszukanie najlepszego klasyfikatora\n",
    "Do klasyfikacji wykorzystano algorytm RandomForest. W tym kroku należało znaleźć najlepsze parametry tego klasyfikatora za pomocą metody grid search. Znaleziony klasyfikator był oceniany miarą weighted recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_measure = 'recall_weighted'\n",
    "tune_parameters = {\n",
    "\t'n_estimators': [130, 140, 150, 160, 170, 180],\n",
    "\t'max_features': ['sqrt', 'log2'] }\n",
    "\n",
    "def search(df, classes):\n",
    "\tdf = df.drop('res_name', axis = 1)\n",
    "\tX_train, X_test, y_train, y_test = create_train_test(df, classes)\n",
    "\trfc = create_random_forest_classifier()\n",
    "\tclf = GridSearchCV(\n",
    "\t\testimator = rfc,\n",
    "\t\tparam_grid = tune_parameters,\n",
    "\t\tscoring = score_measure)\n",
    "\tclf.fit(X_train, y_train)\n",
    "\tbest_rfc = clf.best_estimator_\n",
    "\tprint 'Best params: ', clf.best_params_\n",
    "\ty_true, y_pred = y_test, best_rfc.predict(X_test)\n",
    "\tprint 'Score (' + score_measure + '): ', recall_score(y_true, y_pred, average='weighted')\n",
    "\treturn best_rfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki procedury dla dwóch klasyfikatorów pokazano w tabeli:\n",
    "\n",
    "| klasyfikator | znalezione parametry | weighted recall |\n",
    "|--------------|----------------------|-----------------|\n",
    "| klasy oryginalne | `{'max_features': 'sqrt', 'n_estimators': 160}` | 0.420 |\n",
    "| klasy grupowe | `{'max_features': 'sqrt', 'n_estimators': 160}` | 0.470 |\n",
    "\n",
    "Znalezione klasyfikatory zostały zserializowane do plików za pomocą biblioteki `joblib` z pakietu `sklearn.externals`. Spakowane pliki z klasyfikatorami znajdują się w archiwach `classifiers/es.7z` (klasyfikator operujący na oryginalnych klasach) i `classifiers/esg.7z` (klasyfikator operujący na klasach grupowych)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasyfikacja zbioru testowego\n",
    "W ostatnim kroku poddawano klasyfikacji zbiór testowy dany w pliku `test_data.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(df, es):\n",
    "\tfile = 'test_data.txt'\n",
    "\ttdf = read_data(file, ',')\n",
    "\ttdf = tdf[list(set(tdf.columns).intersection(df.columns))]\n",
    "\ttdf = tdf.fillna(0)\n",
    "\treturn es.predict(tdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki klasyfikacji dla klas oryginalnych znajdują się w pliku `results/classify.txt`, a dla klas grupowych w pliku `results/classifyg.txt`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
